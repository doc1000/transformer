{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    " \n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# variables:\n",
    "d_model: int: # of dimensions in model... hidden layer I think\n",
    "pos: int: position in sequence or sentence\n",
    "i: int: ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "download english to portegeuse samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples, metadata = tfds.load('ted_hrlr_translate/pt_to_en', with_info=True,\n",
    "                              as_supervised=True)\n",
    "train_examples, val_examples = examples['train'], examples['validation']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create custom tokenizer from training dataset, extract sentences and create a list of words \n",
    "tokenizer_en = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "(en.numpy() for pt, en in train_examples), target_vocab_size = 2**13)\n",
    "\n",
    "tokenizer_pt = tfds.features.text.SubwordTextEncoder.build_from_corpus(\n",
    "(pt.numpy() for pt, en in train_examples), target_vocab_size = 2**13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized string is [7915, 1248, 7946, 7194, 13, 2799]\n",
      "The original string: Transformer is awesome\n"
     ]
    }
   ],
   "source": [
    "sample_string = 'Transformer is awesome'\n",
    "\n",
    "tokenized_string = tokenizer_en.encode(sample_string)\n",
    "print('Tokenized string is {}'.format(tokenized_string))\n",
    "\n",
    "original_string = tokenizer_en.decode(tokenized_string)\n",
    "print('The original string: {}'.format(original_string))\n",
    "\n",
    "assert original_string==sample_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7915 ----> T\n",
      "1248 ----> ran\n",
      "7946 ----> s\n",
      "7194 ----> former \n",
      "13 ----> is \n",
      "2799 ----> awesome\n"
     ]
    }
   ],
   "source": [
    "for ts in tokenized_string:\n",
    "    print('{} ----> {}'.format(ts,tokenizer_en.decode([ts])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 20000\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add start and end tokens to input and target\n",
    "# in this case we add the vocab length as start and +=1 as end token\n",
    "def encode(lang1, lang2):\n",
    "    lang1 = [tokenizer_pt.vocab_size] + tokenizer_pt.encode(lang1.numpy()) \\\n",
    "    + [tokenizer_pt.vocab_size+1]\n",
    "   \n",
    "    lang2 = [tokenizer_en.vocab_size] + tokenizer_en.encode(lang2.numpy()) \\\n",
    "    + [tokenizer_en.vocab_size+1] \n",
    "    \n",
    "    return lang1, lang2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep example small and relatively fast, limit length\n",
    "MAX_LENGTH = 40\n",
    "def filter_max_length(x, y, max_length=MAX_LENGTH):\n",
    "    return tf.logical_and(tf.size(x) <= max_length,\n",
    "                         tf.size(y) <= max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# operations in .map() run in graph mode and get graph tensor that doesn't have numpy attribute.  so wrap it up to enable eager tensor with numpy attribute\n",
    "def tf_encode(pt, en):\n",
    "    return tf.py_function(encode, [pt, en], [tf.int64, tf.int64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_examples.map(tf_encode)\n",
    "train_dataset = train_dataset.filter(filter_max_length)\n",
    "# cache the dataset to memory to get a speedup while reading from it\n",
    "train_dataset = train_dataset.cache()\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).padded_batch(\n",
    "    BATCH_SIZE, padded_shapes=([-1], [-1]))\n",
    "train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_examples.map(tf_encode)\n",
    "val_dataset = val_dataset.filter(filter_max_length).padded_batch(BATCH_SIZE, padded_shapes=([-1],[-1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=207688, shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8214, 1259,    5, ...,    0,    0,    0],\n",
       "        [8214,  299,   13, ...,    0,    0,    0],\n",
       "        [8214,   59,    8, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8214,   95,    3, ...,    0,    0,    0],\n",
       "        [8214, 5157,    1, ...,    0,    0,    0],\n",
       "        [8214, 4479, 7990, ...,    0,    0,    0]], dtype=int64)>,\n",
       " <tf.Tensor: id=207689, shape=(64, 40), dtype=int64, numpy=\n",
       " array([[8087,   18,   12, ...,    0,    0,    0],\n",
       "        [8087,  634,   30, ...,    0,    0,    0],\n",
       "        [8087,   16,   13, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [8087,   12,   20, ...,    0,    0,    0],\n",
       "        [8087,   17, 4981, ...,    0,    0,    0],\n",
       "        [8087,   12, 5453, ...,    0,    0,    0]], dtype=int64)>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt_batch, en_batch = next(iter(val_dataset))\n",
    "pt_batch, en_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    \"\"\"\n",
    "    pos:  position in array\n",
    "    i: columnized array of range with length equal to model dimensions\n",
    "    \"\"\"\n",
    "    angle_rates = 1 / np.power(1000, (2 * (i//2)) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads= get_angles(np.arange(position)[:, np.newaxis],\n",
    "                           np.arange(d_model)[np.newaxis, :], d_model)\n",
    "    \n",
    "    # apply sin to even indices in the array: 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    \n",
    "    #apply cos to odd indices in array: 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "    \n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    \n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50, 512)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print(pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking\n",
    "Mask all the pad tokens in the batch of sequence. It ensures that the model does not treat padding as the input. The mask indicates where pad value 0 is present: it outputs a 1 at those locations, and a 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq,0),tf.float32)\n",
    "    \n",
    "    # add extra dimensions to add the padding to the attention logits\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :] # (batch_size, 1,1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207703, shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
       "array([[[[0., 0., 1., 1., 0.]]],\n",
       "\n",
       "\n",
       "       [[[0., 0., 0., 1., 1.]]],\n",
       "\n",
       "\n",
       "       [[[1., 1., 1., 0., 0.]]]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[7,6,0,0,1],[1, 2, 3, 0, 0], [0, 0, 0, 4, 5] ])\n",
    "create_padding_mask(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The look-ahead mask is used to mask the future tokens in a sequence. In other words, the mask indicates which entries should not be used.\n",
    "\n",
    "This means that to predict the third word, only the first and second word will be used. Similarly to predict the fourth word, only the first, second and the third word will be used and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    # creates square matrix masking numbers in columns that are ahead of rows, upper triangle of value 1\n",
    "    return mask # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=207718, shape=(3, 3), dtype=float32, numpy=\n",
       "array([[0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.random.uniform((1,3))\n",
    "temp= create_look_ahead_mask(x.shape[1])\n",
    "x\n",
    "temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaled dot product attention\n",
    "The attention function used by the transformer takes three inputs: Q (query), K (key), V (value). The equation used to calculate the attention weights is:\n",
    "\n",
    "$Attention(Q, K, V) = softmax_{k}(\\frac{QK^T}{\\sqrt{d_{k}}})V$\n",
    "\n",
    "The dot-product attention is scaled by a factor of square root of the depth. This is done because for large values of depth, the dot product grows large in magnitude pushing the softmax function where it has small gradients resulting in a very hard softmax.\n",
    "\n",
    "For example, consider that Q and K have a mean of 0 and variance of 1. Their matrix multiplication will have a mean of 0 and variance of dk. Hence, square root of dk is used for scaling (and not any other number) because the matmul of Q and K should have a mean of 0 and variance of 1, and you get a gentler softmax.\n",
    "\n",
    "The mask is multiplied with -1e9 (close to negative infinity). This is done because the mask is summed with the scaled matrix multiplication of Q and K and is applied immediately before a softmax. The goal is to zero out these cells, and large negative inputs to softmax are near zero in the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate teh attention weights\n",
    "    q, k, v must have matching leading dimensions\n",
    "    k, v must have matching penultimate dimension, ie: seq_len_k = seq_len_v\n",
    "    the mask has diff shapes depending on its type(padding or look ahead)\n",
    "    but it must be broadcastable for addition\n",
    "    \n",
    "    Args:\n",
    "        q: query shape == (..., seq_len_q, depth)\n",
    "        k: key shape == (..., seq_len_k, depth)\n",
    "        v: value shape == (..., seq_len_v, depth_v)\n",
    "        mask: float tensor with shape broadcastable to (..., seq_len_q, seq_len_k)\n",
    "        \n",
    "    Returns:\n",
    "        output, attention_weights\n",
    "    \"\"\"\n",
    "    \n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)# (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "    \n",
    "    # add the mask to the scaled tensor\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    #softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # (..., seq_len_q, seq_len_k)\n",
    "    \n",
    "    output = tf.matmul(attention_weights, v) # (..., seq_len_q, depth_v)\n",
    "    \n",
    "    return output, attention_weights\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the softmax normalization is done on K, its values decide the amount of importance given to Q.\n",
    "\n",
    "The output represents the multiplication of the attention weights and the V (value) vector. This ensures that the words you want to focus on are kept as-is and the irrelevant words are flushed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_out(q, k, v):\n",
    "    temp_out, temp_attn = scaled_dot_product_attention(q,k,v,None)\n",
    "    print('Attention weights are:')\n",
    "    print(temp_attn)\n",
    "    print('Output is:')\n",
    "    print(temp_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0. 1. 0. 0.]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[10.  0.]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "temp_k = tf.constant([[10,0,0],\n",
    "                      [0,10,0],\n",
    "                      [0,0,10],\n",
    "                      [0,0,10]], dtype=tf.float32)  # (4, 3)\n",
    "\n",
    "temp_v = tf.constant([[   1,0],\n",
    "                      [  10,0],\n",
    "                      [ 100,5],\n",
    "                      [1000,6]], dtype=tf.float32)  # (4, 2)\n",
    "# this query aligns witht eh second key so the second value is returned\n",
    "temp_q = tf.constant([[0, 10, 0]], dtype=tf.float32) # (1,3)\n",
    "\n",
    "print_out(temp_q, temp_k, temp_v)\n",
    "#temp_q, temp_k, temp_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.  0.  0.5 0.5]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[550.    5.5]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns with a repeated key (third and fourth),\n",
    "# so all associated values get averaged\n",
    "temp_q = tf.constant([[0, 0, 10]], dtype=tf.float32) # (1,3)\n",
    "print_out(temp_q, temp_k, temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention weights are:\n",
      "tf.Tensor([[0.5 0.5 0.  0. ]], shape=(1, 4), dtype=float32)\n",
      "Output is:\n",
      "tf.Tensor([[5.5 0. ]], shape=(1, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# This query aligns equally with the first and second key, \n",
    "# so their values get averaged.\n",
    "temp_q = tf.constant([[10, 10, 0]], dtype=tf.float32)  # (1, 3)\n",
    "print_out(temp_q, temp_k, temp_v)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-head attention\n",
    "Multi-head attention consists of four parts:\n",
    "\n",
    "    * Linear layers and split into heads.\n",
    "    * Scaled dot-product attention.\n",
    "    * Concatenation of heads.\n",
    "    * Final linear layer.\n",
    "\n",
    "Each multi-head attention block gets three inputs; Q (query), K (key), V (value). These are put through linear (Dense) layers and split up into multiple heads.\n",
    "\n",
    "The scaled_dot_product_attention defined above is applied to each head (broadcasted for efficiency). An appropriate mask must be used in the attention step. The attention output for each head is then concatenated (using tf.transpose, and tf.reshape) and put through a final Dense layer.\n",
    "\n",
    "Instead of one single attention head, Q, K, and V are split into multiple heads because it allows the model to jointly attend to information at different positions from different representational spaces. After the split each head has a reduced dimensionality, so the total computation cost is the same as a single head attention with full dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads=num_heads\n",
    "        self.d_model=d_model\n",
    "        \n",
    "        assert d_model % self.num_heads == 0\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.wq = tf.keras.layers.Dense(d_model)\n",
    "        self.wk = tf.keras.layers.Dense(d_model)\n",
    "        self.wv = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"split the last dimension into (num_heads, depth)\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        # x currently (batch size, seq_length, d_model)\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        # let seq_len float to accomodate splitting d_model into heads and depth\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "    \n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "        \n",
    "        #run q, k, v arrays thru dense layers\n",
    "        q = self.wq(q) # (batch_size, seq_len, d_moel)\n",
    "        k = self.wk(k) # (batch_size, seq_len, d_moel)\n",
    "        v = self.wv(v) # (batch_size, seq_len, d_moel)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size) # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size) # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size) # (batch_size, num_heads, seq_len_v, depth)\n",
    "        \n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)\n",
    "        \n",
    "        #transpose num_heads and seq_len, so heads and depth can be concatenated\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3]) # (batch_size, seq_len_q, num_heads, depth)\n",
    "        \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model)) # (batch_size, seq_len_q, d_model)\n",
    "        \n",
    "        output = self.dense(concat_attention) # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([1, 60, 512]), TensorShape([1, 8, 60, 60]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_mha = MultiHeadAttention(512, 8)\n",
    "y = tf.random.uniform((1, 60, 512))\n",
    "out, attn = temp_mha(y,y,y,mask=None)\n",
    "out.shape, attn.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point wise feed forward network\n",
    "\n",
    "PWFFN consists of two dense fully connected layers with a ReLU activation in between\n",
    "I'm not sure why there are two layers here and not just the single layer with activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(d_model, dff):\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Dense(dff, activation = 'relu'), #(batch_size, seq_len, dff)\n",
    "    tf.keras.layers.Dense(d_model) # (batch_size, seq_len, d_model)        \n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 60, 512])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_ffn = point_wise_feed_forward_network(512, 2048)\n",
    "sample_ffn(tf.random.uniform((1,60,512))).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder\n",
    "\n",
    "takes embedded inputs, runs through multiple encoder layers, returns encoded output for each token in sequence\n",
    "\n",
    "## Encoder Layer\n",
    "\n",
    "consists of a self attention layer followed by feed forward layer, with normalization after each layer.\n",
    "\n",
    "The output of each sublayer is LayerNorm(x + sublayer(x)).  normalization done on the last (d_model) axis.  There are N encoder layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        attn_output, _ = self.mha(x,x,x,mask) # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(x + attn_output) # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        ffn_output = self.ffn(out1) # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        out2 = self.layernorm2(out1 + ffn_output) # (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        return out2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 43, 512])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
    "sample_encoder_layer_out = sample_encoder_layer(tf.random.uniform((64,43,512)),training=False, mask=None)\n",
    "\n",
    "sample_encoder_layer_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder\n",
    "The encoder consists of:\n",
    "    1. Input Embedding\n",
    "    2. Positional Encoding\n",
    "    3. N encoder layers\n",
    "    \n",
    "Teh input is put through an embedding which is summed with the positional encoding.  The output of this summation is the input to the encoder layers.  The output of the encoder is the input to the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                maximum_position_encoding, rate = 0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
    "        self.pos_encoding = positional_encoding(maximum_position_encoding, \n",
    "                                               self.d_model)\n",
    "        \n",
    "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate)\n",
    "                           for _ in range(num_layers)]\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, training, mask):\n",
    "        \n",
    "        seq_len = tf.shape(x)[1]\n",
    "        \n",
    "        # adding embedding and position encoding\n",
    "        x = self.embedding(x) # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        \n",
    "        x = self.dropout(x, training=training)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.enc_layers[i](x, training, mask)\n",
    "            \n",
    "        return x # (batch_size, input_seq_len, d_model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 62, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                        dff=2048, input_vocab_size=8500,\n",
    "                        maximum_position_encoding=10000)\n",
    "temp_input = tf.random.uniform((64,62), dtype=tf.int64, minval=0,\n",
    "                              maxval=200)\n",
    "\n",
    "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
    "\n",
    "print(sample_encoder_output.shape) # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder layer\n",
    "\n",
    "each layer consists of \n",
    "    1. self attention with lookahead (so future words won't be referenced) and padding mask (so shorter or longer phrases can be used)\n",
    "    2. encoder attention referencing encoder output, with padding mask.  v(value) and k(key) receive encoder output as inputs.  Q (query) receieves output from the self-attention sublayer\n",
    "    3. point wise feed forward layer\n",
    "    \n",
    "each layer uses a residual connection with layer normalization.  The output of each sublayer is LayerNorm(x + sublayer(x)) with normalization on the last axis (d_model)\n",
    "\n",
    "N decoder layers\n",
    "\n",
    "Q recieves attention from decoder first self-attention block and k receives encoder output, so the weights represent importance given to the decoder's input by the decoder's output.  the next word is predicted by looking at the encoder's output and self-attending to its own input (tokens around target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self,d_model, num_heads, dff, rate=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.mha1 = MultiHeadAttention(d_model, num_heads) # self attention\n",
    "        self.mha2 = MultiHeadAttention(d_model, num_heads) # encoder attention\n",
    "        \n",
    "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
    "        \n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
    "        \n",
    "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
    "        #enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        \n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask) # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1,training=training)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        \n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask) # (batch_size, target_seq_len (from out1 as query), d_model)\n",
    "        attn2 = self.dropout2(attn2,training=training)\n",
    "        out2 = self.layernorm2(attn2 + out1)\n",
    "        \n",
    "        ffn_output = self.ffn(out2) # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output,training=training)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "        \n",
    "        return out3, attn_weights_block1, attn_weights_block2\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 23, 512])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
    "\n",
    "sample_decoder_layer_out, _, _ = sample_decoder_layer(\n",
    "    tf.random.uniform((64,23,512)),\n",
    "    sample_encoder_layer_out,\n",
    "    False, None, None)\n",
    "\n",
    "sample_decoder_layer_out.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder\n",
    "\n",
    "The decoder consists of:\n",
    "    1. Output embedding\n",
    "    2. Positional encoding\n",
    "    3. N decoder layers\n",
    "\n",
    "The target is put through an embedding which is summed with the positional encoding.  The output of this summation is the input to the decoder layers.  The output of the decoder is the input to the final linear layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "  def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
    "               maximum_position_encoding, rate=0.1):\n",
    "    super(Decoder, self).__init__()\n",
    "\n",
    "    self.d_model = d_model\n",
    "    self.num_layers = num_layers\n",
    "    \n",
    "    self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
    "    self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
    "    \n",
    "    self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) \n",
    "                       for _ in range(num_layers)]\n",
    "    self.dropout = tf.keras.layers.Dropout(rate)\n",
    "    \n",
    "  def call(self, x, enc_output, training, \n",
    "           look_ahead_mask, padding_mask):\n",
    "\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    attention_weights = {}\n",
    "    \n",
    "    x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "    x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "    x += self.pos_encoding[:, :seq_len, :]\n",
    "    \n",
    "    x = self.dropout(x, training=training)\n",
    "\n",
    "    for i in range(self.num_layers):\n",
    "      x, block1, block2 = self.dec_layers[i](x, enc_output, training,\n",
    "                                             look_ahead_mask, padding_mask)\n",
    "      \n",
    "      attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "      attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "    \n",
    "    # x.shape == (batch_size, target_seq_len, d_model)\n",
    "    return x, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
    "                        dff=2048, target_vocab_size=8000,\n",
    "                        maximum_position_encoding=5000)\n",
    "temp_input = tf.random.uniform((64,26), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "output, attn = sample_decoder(temp_input,\n",
    "                            enc_output=sample_encoder_output,\n",
    "                             training=False,\n",
    "                             look_ahead_mask = None,\n",
    "                             padding_mask = None)\n",
    "\n",
    "output.shape, attn['decoder_layer2_block2'].shape\n",
    "# (batch_shape, num_heads, target_seq_len, input_seq_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the Transformer\n",
    "\n",
    "consists of the encoder, decoder and final linear layer.  The output of the decoder is the input to the linear layer and its output is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
    "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "    \n",
    "        self.encoder = Encoder(num_layers, d_model, num_heads, dff,\n",
    "                               input_vocab_size, pe_input, rate)\n",
    "    \n",
    "        self.decoder = Decoder(num_layers, d_model, num_heads, dff,\n",
    "                          target_vocab_size, pe_target, rate)\n",
    "    \n",
    "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
    "    \n",
    "    def call(self, inp, tar, training, enc_padding_mask, \n",
    "             look_ahead_mask, dec_padding_mask):\n",
    "        \n",
    "        enc_output = self.encoder(inp, training, enc_padding_mask) # (batch_size, inp_seq_len, d_model)\n",
    "        \n",
    "        #dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attention_weights = self.decoder(\n",
    "        tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output) # batch_size, tar_seq_len, target_vocab_size)\n",
    "        \n",
    "        return final_output, attention_weights\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([64, 36, 8000])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_transformer = Transformer(\n",
    "num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
    "input_vocab_size=8500, target_vocab_size=8000,\n",
    "pe_input=10000, pe_target=6000)\n",
    "\n",
    "temp_input = tf.random.uniform((64, 38), dtype=tf.int64, minval=0, maxval=200)\n",
    "temp_target = tf.random.uniform((64, 36), dtype=tf.int64, minval=0, maxval=200)\n",
    "\n",
    "fn_out, _ = sample_transformer(temp_input, temp_target, training=False,\n",
    "                              enc_padding_mask=None,\n",
    "                              look_ahead_mask=None,\n",
    "                              dec_padding_mask=None)\n",
    "\n",
    "fn_out.shape # (batch_size, tar_seq_len, target_vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Hyperparameters\n",
    "\n",
    "reduce dimensions to keep example small and manageable\n",
    "for the original transformer model: num_layers=6, d_model=512, dff=2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = 4\n",
    "d_model = 128\n",
    "dff = 512\n",
    "num_heads = 8\n",
    "\n",
    "\n",
    "input_vocab_size = tokenizer_pt.vocab_size + 2\n",
    "target_vocab_size = tokenizer_en.vocab_size + 2\n",
    "dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer\n",
    "\n",
    "Use the Adam optimizer with a custom learning rate scheduler according to the formula in the paper\n",
    "\n",
    "## $lrate = d_{model}^{-0.5}*min(step\\_num^{-0.5},step\\_num*warmup\\_steps^{-1.5})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "  def __init__(self, d_model, warmup_steps=4000):\n",
    "    super(CustomSchedule, self).__init__()\n",
    "    \n",
    "    self.d_model = d_model\n",
    "    self.d_model = tf.cast(self.d_model, tf.float32)\n",
    "\n",
    "    self.warmup_steps = warmup_steps\n",
    "    \n",
    "  def __call__(self, step):\n",
    "    arg1 = tf.math.rsqrt(step)\n",
    "    arg2 = step * (self.warmup_steps ** -1.5)\n",
    "    \n",
    "    return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(d_model)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, \n",
    "                                     epsilon=1e-9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Train Step')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_learning_rate_schedule = CustomSchedule(d_model)\n",
    "\n",
    "plt.plot(temp_learning_rate_schedule(tf.range(40000, dtype=tf.float32)))\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.xlabel(\"Train Step\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss and Metrics\n",
    "\n",
    "Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    \n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(num_layers, d_model, num_heads, dff,\n",
    "                         input_vocab_size, target_vocab_size,\n",
    "                         pe_input=input_vocab_size,\n",
    "                         pe_target=target_vocab_size,\n",
    "                         rate=dropout_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    # used in the 2nd attention block (encoder attention) in the decoder\n",
    "    # This padding mask is used to mask the encoder outputs\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "    \n",
    "    #used in the 1st attention block (self-attention) in the decoder\n",
    "    # It s used to pad and mask future tokens in the input received by the decoder\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the checkpoint path and the checkpoint manager.  This will be used to save checkpoints every n epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest checkpoint restored!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"./checkpoints/train\"\n",
    "\n",
    "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
    "                          optimizer=optimizer)\n",
    "\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
    "\n",
    "# if a checkpoint exists, restore the latest checkpoint\n",
    "if ckpt_manager.latest_checkpoint:\n",
    "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
    "    print('Latest checkpoint restored!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The @tf.function trace-compiles train_steps into a TF graph for\n",
    "faster execution.  The function specializes to teh precise shape of the argument\n",
    "tensors.  To avoid re-tracing due to the variable sequence lengths or ariable\n",
    "batch sizes (the last batch is smaller), use input_signature to specify \n",
    "more generic shapes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_step_signature = [\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
    "]\n",
    "\n",
    "@tf.function(input_signature=train_step_signature)\n",
    "def train_step(inp, tar):\n",
    "    tar_inp = tar[:, :-1]\n",
    "    tar_real = tar[:, 1:]\n",
    "    \n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, _ = transformer(inp, tar_inp,\n",
    "                                    True,\n",
    "                                    enc_padding_mask,\n",
    "                                    combined_mask,\n",
    "                                    dec_padding_mask)\n",
    "        loss = loss_function(tar_real, predictions)\n",
    "    \n",
    "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(tar_real, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Portuguese is used as the input language and English is the target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Batch 0 Loss 0.4713 Accuracy 0.3347\n",
      "Epoch 1 Batch 50 Loss 0.5143 Accuracy 0.3541\n",
      "Epoch 1 Batch 100 Loss 0.5107 Accuracy 0.3530\n",
      "Epoch 1 Batch 150 Loss 0.5128 Accuracy 0.3515\n",
      "Epoch 1 Batch 200 Loss 0.5166 Accuracy 0.3500\n",
      "Epoch 1 Batch 250 Loss 0.5206 Accuracy 0.3495\n",
      "Epoch 1 Batch 300 Loss 0.5239 Accuracy 0.3494\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    start = time.time()\n",
    "    \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    # inp -> portuguese, tar -> english\n",
    "    for (batch, (inp, tar)) in enumerate(train_dataset):\n",
    "        train_step(inp, tar)\n",
    "        \n",
    "        if batch % 50 == 0:\n",
    "            print ('Epoch {} Batch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "            epoch + 1, batch, train_loss.result(), train_accuracy.result()))\n",
    "            \n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        ckpt_save_path = ckpt_manager.save()\n",
    "        print('Saving checkpoint for epoch {} at {}'.format(\n",
    "        epoch + 1, ckpt_save_path))\n",
    "        \n",
    "    print ('Epoch {} Loss {:.4f} Accuracy {:.4f}'.format(\n",
    "    epoch+1, train_loss.result(), train_accuracy.result()))\n",
    "    print('{:.2f} minutes elapsed'.format((time.time()-start)/60))\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(inp_sentence):\n",
    "  start_token = [tokenizer_pt.vocab_size]\n",
    "  end_token = [tokenizer_pt.vocab_size + 1]\n",
    "  \n",
    "  # inp sentence is portuguese, hence adding the start and end token\n",
    "  inp_sentence = start_token + tokenizer_pt.encode(inp_sentence) + end_token\n",
    "  encoder_input = tf.expand_dims(inp_sentence, 0)\n",
    "  \n",
    "  # as the target is english, the first word to the transformer should be the\n",
    "  # english start token.\n",
    "  decoder_input = [tokenizer_en.vocab_size]\n",
    "  output = tf.expand_dims(decoder_input, 0)\n",
    "    \n",
    "  for i in range(MAX_LENGTH):\n",
    "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(\n",
    "        encoder_input, output)\n",
    "  \n",
    "    # predictions.shape == (batch_size, seq_len, vocab_size)\n",
    "    predictions, attention_weights = transformer(encoder_input, \n",
    "                                                 output,\n",
    "                                                 False,\n",
    "                                                 enc_padding_mask,\n",
    "                                                 combined_mask,\n",
    "                                                 dec_padding_mask)\n",
    "    \n",
    "    # select the last word from the seq_len dimension\n",
    "    predictions = predictions[: ,-1:, :]  # (batch_size, 1, vocab_size)\n",
    "\n",
    "    predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "    \n",
    "    # return the result if the predicted_id is equal to the end token\n",
    "    if predicted_id == tokenizer_en.vocab_size+1:\n",
    "      return tf.squeeze(output, axis=0), attention_weights\n",
    "    \n",
    "    # concatentate the predicted_id to the output which is given to the decoder\n",
    "    # as its input.\n",
    "    output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "  return tf.squeeze(output, axis=0), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_weights(attention, sentence, result, layer):\n",
    "  fig = plt.figure(figsize=(16, 8))\n",
    "  \n",
    "  sentence = tokenizer_pt.encode(sentence)\n",
    "  \n",
    "  attention = tf.squeeze(attention[layer], axis=0)\n",
    "  \n",
    "  for head in range(attention.shape[0]):\n",
    "    ax = fig.add_subplot(2, 4, head+1)\n",
    "    \n",
    "    # plot the attention weights\n",
    "    ax.matshow(attention[head][:-1, :], cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 10}\n",
    "    \n",
    "    ax.set_xticks(range(len(sentence)+2))\n",
    "    ax.set_yticks(range(len(result)))\n",
    "    \n",
    "    ax.set_ylim(len(result)-1.5, -0.5)\n",
    "        \n",
    "    ax.set_xticklabels(\n",
    "        ['<start>']+[tokenizer_pt.decode([i]) for i in sentence]+['<end>'], \n",
    "        fontdict=fontdict, rotation=90)\n",
    "    \n",
    "    ax.set_yticklabels([tokenizer_en.decode([i]) for i in result \n",
    "                        if i < tokenizer_en.vocab_size], \n",
    "                       fontdict=fontdict)\n",
    "    \n",
    "    ax.set_xlabel('Head {}'.format(head+1))\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sentence, plot=''):\n",
    "  result, attention_weights = evaluate(sentence)\n",
    "  \n",
    "  predicted_sentence = tokenizer_en.decode([i for i in result \n",
    "                                            if i < tokenizer_en.vocab_size])  \n",
    "\n",
    "  print('Input: {}'.format(sentence))\n",
    "  print('Predicted translation: {}'.format(predicted_sentence))\n",
    "  \n",
    "  if plot:\n",
    "    plot_attention_weights(attention_weights, sentence, result, plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translate(\"este  um problema que temos que resolver.\")\n",
    "print (\"Real translation: this is a problem we have to solve .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
